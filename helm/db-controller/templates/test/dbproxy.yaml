apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Release.Name }}-dbproxy-test
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "db-controller.labels" . | nindent 4 }}
    app.kubernetes.io/component: dbproxy-test
  annotations:
    "helm.sh/hook": "test"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: {{ .Release.Name }}-dbproxy-test
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "db-controller.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": "test"
rules:
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - get
      - list
      - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: {{ .Release.Name }}-dbproxy-test
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "db-controller.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": "test"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: {{ .Release.Name }}-dbproxy-test
subjects:
  - kind: ServiceAccount
    name: {{ .Release.Name }}-dbproxy-test
    namespace: {{ .Release.Namespace }}
---
apiVersion: v1
kind: Secret
metadata:
  name: {{ .Release.Name }}-dbproxy-test
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "db-controller.labels" . | nindent 4 }}
  annotations:
    # ensure this runs on the new db-controller, not the existing one
    "helm.sh/hook": "test"
    "helm.sh/hook-weight": "-5"
type: Opaque
data:
  uri_dsn.txt: {{ printf "postgres://myuser:mypassword@%s-dbproxy-test-db.%s.svc:5432/mydb?sslmode=disable" .Release.Name .Release.Namespace | b64enc | quote }}
  password: {{ "mypassword" | b64enc }}
---
# Keep this separate from test so it can get a chance to setup
# before the mutating webhook test runs
apiVersion: persistance.atlas.infoblox.com/v1
kind: DatabaseClaim
metadata:
  name: {{ .Release.Name }}-dbproxy-test
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "db-controller.labels" . | nindent 4 }}
  annotations:
    # ensure this runs on the new db-controller, not the existing one
    "helm.sh/hook": "test"
spec:
  class: {{ .Values.dbController.class }}
  databaseName: mydb
  secretName: {{ .Release.Name }}-dbproxy-test-claims
  # Ensure this is set to true, we don't want to use aws
  useExistingSource: true
  userName: myuser
  appId: "removethispropertyfromcrd"
  dsnName: "dsn.txt"
  type: "postgres"
  sourceDataFrom:
    type: database
    database:
      dsn: {{ printf "postgres://myuser:@%s-dbproxy-test-db.%s.svc:5432/mydb?sslmode=disable" .Release.Name .Release.Namespace | quote }}
      secretRef:
        namespace: {{ .Release.Namespace }}
        name: {{ .Release.Name }}-dbproxy-test
---
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-dbproxy-test-db
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "db-controller.labels" . | nindent 4 }}
spec:
  selector:
    app: dbproxy-test-db
  ports:
    - protocol: TCP
      port: 5432
      targetPort: 5432
---
apiVersion: v1
kind: Pod
metadata:
  name: {{ .Release.Name }}-dbproxy-test-db
  namespace: {{ .Release.Namespace }}
  labels:
    app: dbproxy-test-db
    {{- include "db-controller.labels" . | nindent 4 }}
spec:
  containers:
    - name: postgres
      image: postgres:15
      env:
        - name: POSTGRES_USER
          value: "myuser"
        - name: POSTGRES_PASSWORD
          value: "mypassword"
        - name: POSTGRES_DB
          value: "mydb"
---
apiVersion: v1
kind: Pod
metadata:
  name: {{ .Release.Name }}-dbproxy-test-proxy
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "db-controller.labels" . | nindent 4 }}
    persistance.atlas.infoblox.com/databaseclaim: {{ .Release.Name }}-dbproxy-test
    persistance.atlas.infoblox.com/class: {{ .Values.dbController.class | quote }}
  annotations:
    helm.sh/hook: test
    helm.sh/hook-delete-policy: "before-hook-creation,hook-succeeded"
spec:
  serviceAccountName: {{ .Release.Name }}-dbproxy-test
  initContainers:
    - name: init
      image: postgres:15
      env:
        - name: PGCONNECT_TIMEOUT
          value: "2"
      command:
        - /bin/sh
        - -c
        - |
          cat /etc/secrets/uri_dsn.txt
          for i in $(seq 1 10); do
            echo "Attempt $i: Connecting to PostgreSQL..."
            if psql $(cat /etc/secrets/uri_dsn.txt) -c 'SELECT 1'; then
              echo "Connection successful!"
              exit 0
            fi
            echo "Failed to connect. Retrying in 5 seconds..."
            sleep 5
          done
          echo "Failed to connect after 20 attempts. Exiting."
          exit 1
      volumeMounts:
        - name: dsn-volume
          mountPath: /etc/secrets
          readOnly: true
  containers:
    - name: wait
      image: {{ .Values.tools.kubectl.repository }}:{{ .Values.tools.kubectl.tag }}
      securityContext:
        runAsUser: 0
        capabilities:
          add:
            - SYS_PTRACE
            - KILL
      command:
        - /bin/bash
        - -cx
        - |
          echo "Waiting for sidecar to be ready..."
          kubectl wait -n '{{ .Release.Namespace }}' --for=condition=ready pod $HOSTNAME --timeout=300s
          echo "Sidecar is ready, killing dbproxy in 1s."
          kill -s INT $(pidof /usr/bin/dbproxy)
          exit 0
  shareProcessNamespace: true
  # Sidecar has a liveness probe, allow it to restart
  restartPolicy: Never
  volumes:
    - name: dsn-volume
      secret:
        secretName: {{ .Release.Name }}-dbproxy-test
---
